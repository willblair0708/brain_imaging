{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv3DTranspose, BatchNormalization, LeakyReLU, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (160, 160, 192, 1)\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with max pooling\n",
    "model.add(Conv3D(32, (3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define the input shape\n",
    "img_shape = (160, 160, 192, 2)\n",
    "latent_dim = 100\n",
    "\n",
    "# Create a generator model\n",
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(128 * 20 * 20 * 24, activation=\"relu\", input_dim=latent_dim))\n",
    "generator.add(Reshape((20, 20, 24, 128)))\n",
    "generator.add(Conv3DTranspose(128, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\"))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Conv3DTranspose(64, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\"))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Conv3DTranspose(2, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\", activation='tanh'))\n",
    "\n",
    "# Create a discriminator model\n",
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv3D(32, kernel_size=(3, 3, 3), strides=(2, 2, 2), input_shape=img_shape, padding=\"same\"))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Conv3D(64, kernel_size=(3, 3, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_shape = (1, 182, 218, 182)\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            nn.Linear(128 * 5 * 5 * 6, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "    \n",
    "model = ConvNet()\n",
    "\n",
    "# Define the input shape\n",
    "img_shape = (2, 160, 160, 192)\n",
    "latent_dim = 100\n",
    "\n",
    "# Define the generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 163840),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(163840)\n",
    "        )\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose3d(32, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layer(x)\n",
    "        x = x.view(x.shape[0], 128, 20, 20, 24) # reshaping tensor\n",
    "        x = self.conv_layers(x)\n",
    "        return x\n",
    "    \n",
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout3d(0.25),\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout3d(0.25)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(163840, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n",
    "# Create the discriminator and generator models\n",
    "discriminator = Discriminator()\n",
    "generator = Generator(latent_dim)\n",
    "\n",
    "# Define the loss function and optimizer for the discriminator and generator\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Define the input shape for the real and fake images\n",
    "real_imgs = torch.zeros((32, *input_shape))\n",
    "fake_imgs = torch.zeros((32, latent_dim))\n",
    "\n",
    "# Train the models\n",
    "for epoch in range(200):\n",
    "    # Train the discriminator\n",
    "    optimizer_D.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
