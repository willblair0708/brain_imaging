{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "# from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv3DTranspose, BatchNormalization, LeakyReLU, concatenate\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # Define the input shape\n",
    "# input_shape = (160, 160, 192, 1)\n",
    "\n",
    "# # Create a sequential model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add convolutional layers with max pooling\n",
    "# model.add(Conv3D(32, (3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# # Add fully connected layers\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Define the input shape\n",
    "# img_shape = (160, 160, 192, 2)\n",
    "# latent_dim = 100\n",
    "\n",
    "# # Create a generator model\n",
    "# generator = Sequential()\n",
    "\n",
    "# generator.add(Dense(128 * 20 * 20 * 24, activation=\"relu\", input_dim=latent_dim))\n",
    "# generator.add(Reshape((20, 20, 24, 128)))\n",
    "# generator.add(Conv3DTranspose(128, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\"))\n",
    "# generator.add(BatchNormalization(momentum=0.8))\n",
    "# generator.add(LeakyReLU(alpha=0.2))\n",
    "# generator.add(Conv3DTranspose(64, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\"))\n",
    "# generator.add(BatchNormalization(momentum=0.8))\n",
    "# generator.add(LeakyReLU(alpha=0.2))\n",
    "# generator.add(Conv3DTranspose(2, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\", activation='tanh'))\n",
    "\n",
    "# # Create a discriminator model\n",
    "# discriminator = Sequential()\n",
    "\n",
    "# discriminator.add(Conv3D(32, kernel_size=(3, 3, 3), strides=(2, 2, 2), input_shape=img_shape, padding=\"same\"))\n",
    "# discriminator.add(LeakyReLU(alpha=0.2))\n",
    "# discriminator.add(Dropout(0.25))\n",
    "# discriminator.add(Conv3D(64, kernel_size=(3, 3, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 182, 218, 182)\n",
    "\n",
    "nc = 1 # num channels\n",
    "\n",
    "ngf = 32 # size of feature maps in generator\n",
    "\n",
    "ndf = 32 # size of feature maps in discriminator\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "lr = 0.0002\n",
    "\n",
    "betas = (0.5, 0.999) # beta1 hyperparameter for Adam optimizers\n",
    "\n",
    "ngpu = 1 # number of GPUs available, 0 for CPU mode\n",
    "\n",
    "batch_size = 128 # batch size during training\n",
    "\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(\n",
    "            # input is 1 x 182 x 218 x 182\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            # input is 32 x 91 x 109 x 91\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            # input is 64 x 46 x 55 x 46\n",
    "            nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            # input is 128 x 23 x 28 x 23\n",
    "            nn.Linear(128 * 23 * 28 * 23, latent_dim),\n",
    "            nn.BatchNorm3d(latent_dim),\n",
    "            nn.LeakyReLU()\n",
    "            # nn.Linear(128, 64),\n",
    "            # nn.Linear(64, 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Sigmoid(), # is this needed?\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_model = ConvNet()\n",
    "t2_model = ConvNet()\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# randomly initializing weights\n",
    "t1_model.apply(weights_init)\n",
    "t2_model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "img_shape = (2, 160, 160, 192)\n",
    "\n",
    "# Define the generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 23 * 28 * 23),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(163840)\n",
    "        )\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose3d(32, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layer(x)\n",
    "        x = x.view(x.shape[0], 128, 23, 28, 23) # reshaping tensor\n",
    "        x = self.conv_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout3d(0.25),\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout3d(0.25),\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(64 * 23* 28 * 23, 128),\n",
    "            # nn.LeakyReLU(0.2), #inplace=True\n",
    "            # nn.Linear(128, 64),\n",
    "            # nn.LeakyReLU(0.2), #inplace=True\n",
    "            # nn.Linear(64, 1),\n",
    "            nn.Linear(64 * 23 * 28 * 23, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator and generator models\n",
    "discriminator = Discriminator()\n",
    "generator = Generator(latent_dim)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "# Define the loss function and optimizer for the discriminator and generator\n",
    "adversarial_loss = nn.BCELoss()\n",
    "generative_loss = nn.MSELoss()\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "# Define the input shape for the real and fake images\n",
    "real_imgs = torch.zeros((32, *input_shape))\n",
    "fake_imgs = torch.zeros((32, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for handling NIfTI files\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, t1w_files, t2w_files, fa_files, adc_files, transform=None):\n",
    "        self.t1w_files = t1w_files\n",
    "        self.t2w_files = t2w_files\n",
    "        self.fa_files = fa_files\n",
    "        self.adc_files = adc_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t1w_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1w_image = nib.load(self.t1w_files[idx]).get_fdata()\n",
    "        t2w_image = nib.load(self.t2w_files[idx]).get_fdata()\n",
    "        fa_image = nib.load(self.fa_files[idx]).get_fdata()\n",
    "        adc_image = nib.load(self.adc_files[idx]).get_fdata()\n",
    "\n",
    "        input_image = np.stack([t1w_image, t2w_image], axis=0)\n",
    "        target_image = np.stack([fa_image, adc_image], axis=0)\n",
    "\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "            target_image = self.transform(target_image)\n",
    "\n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', 'data')\n",
    "\n",
    "# Replace these lists with the paths to your training dataset\n",
    "t1w_files = []\n",
    "t2w_files = []\n",
    "fa_files = []\n",
    "adc_files = []\n",
    "\n",
    "dataset = BrainDataset(t1w_files, t2w_files, fa_files, adc_files, transform=Compose([torch.tensor]))\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 0 for ADC, 1 for FA\n",
    "output_modality = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "# Train the models\n",
    "for epoch in range(num_epochs):\n",
    "    # # Train the discriminator\n",
    "    # optimizer_D.zero_grad()\n",
    "    for i, inputs, targets in enumerate(tqdm(dataloader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # update D: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # train with all-real batch\n",
    "        discriminator.zero_grad()\n",
    "        real_image = targets[output_modality]\n",
    "        real_label = torch.ones(real_image.shape[0], 1).cuda()\n",
    "        real_prediction = discriminator(real_image)\n",
    "        real_loss = adversarial_loss(real_prediction, real_label)\n",
    "        real_loss.backward()\n",
    "\n",
    "        # create latent space and update D with fake image\n",
    "        t1_latent = t1_model(inputs[0]) \n",
    "        t2_latent = t2_model(inputs[1])\n",
    "        # TODO: change to concat\n",
    "        latent = t1_latent + t2_latent\n",
    "        fake_image = generator(latent)\n",
    "        fake_labels = torch.zeros(fake_image.shape[0], 1).cuda()\n",
    "        fake_predictions = discriminator(fake_image.detach())\n",
    "        fake_loss = adversarial_loss(fake_predictions, fake_labels)\n",
    "        fake_loss.backward()\n",
    "\n",
    "        discriminator_loss = real_loss + fake_loss\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # update G network: maximize log(D(G(z)))\n",
    "        generator.zero_grad()\n",
    "        t1_model.zero_grad()\n",
    "        t2_model.zero_grad()\n",
    "\n",
    "        fake = generator(latent)\n",
    "        fake_prediction = discriminator(fake)\n",
    "        errG = adversarial_loss(fake_prediction, real_label)\n",
    "        errR = generative_loss(fake, targets[output_modality])\n",
    "        generator_loss = errG + errR\n",
    "        generator_loss.backward()\n",
    "        optimizer_G.step()        \n",
    "\n",
    "        # output training stats\n",
    "        #if i % 50 == 0:\n",
    "        G_losses.append(generator_loss.item())\n",
    "        D_losses.append(discriminator_loss.item())\n",
    "\n",
    "        # Print the losses\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Discriminator Loss: %.4f, Generator Loss: %.4f\"\n",
    "                  % (epoch, num_epochs, i, len(dataloader), discriminator_loss.item(), generator_loss.item()))\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
