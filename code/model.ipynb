{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install nibabel tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import Compose\n","import nibabel as nib\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Custom dataset class for handling NIfTI files\n","class BrainDataset(Dataset):\n","    def __init__(self, t1w_files, t2w_files, fa_files, adc_files, transform=None):\n","        self.t1w_files = t1w_files\n","        self.t2w_files = t2w_files\n","        self.fa_files = fa_files\n","        self.adc_files = adc_files\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.t1w_files)\n","\n","    def __getitem__(self, idx):\n","        t1w_image = nib.load(self.t1w_files[idx]).get_fdata()\n","        t2w_image = nib.load(self.t2w_files[idx]).get_fdata()\n","        fa_image = nib.load(self.fa_files[idx]).get_fdata()\n","        adc_image = nib.load(self.adc_files[idx]).get_fdata()\n","\n","        input_image = np.stack([t1w_image, t2w_image], axis=0)\n","        target_image = np.stack([fa_image, adc_image], axis=0)\n","\n","        if self.transform:\n","            input_image = self.transform(input_image)\n","            target_image = self.transform(target_image)\n","\n","        return input_image, target_image\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.middle = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        enc = self.encoder(x)\n","        middle = self.middle(enc)\n","        dec = self.decoder(middle)\n","        out = self.final(dec)\n","        return out\n","\n","# Function for initializing the U-Net model\n","def initialize_unet(in_channels, out_channels):\n","    return UNet(in_channels, out_channels)\n","\n","# Function for training the U-Net model\n","def train_unet(unet, dataloader, device, epochs=100, learning_rate=0.001):\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(unet.parameters(), lr=learning_rate)\n","\n","    unet.train()\n","    unet.to(device)\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for inputs, targets in tqdm(dataloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = unet(inputs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloader)}\")\n","\n","    print(\"Training completed.\")\n","\n","if __name__ == \"__main__\":\n","    data_dir = os.path.join('..', 'data')\n","\n","    # Replace these lists with the paths to your training dataset\n","    t1w_files = []\n","    t2w_files = []\n","    fa_files = []\n","    adc_files = []\n","\n","    dataset = BrainDataset(t1w_files, t2w_files, fa_files, adc_files, transform=Compose([torch.tensor]))\n","    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2)\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    unet = initialize_unet(in_channels=2, out_channels=2)\n","    train_unet(unet, dataloader, device, epochs=100, learning_rate=0.001)\n","\n","    # Save the trained model\n","    torch.save(unet.state_dict(), os.path.join(data_dir, \"unet_model.pth\"))\n","\n","    print(\"Model saved.\")\n","\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
