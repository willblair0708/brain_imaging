{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nibabel\n","  Using cached nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n","Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/environment10/lib/python3.9/site-packages (4.64.1)\n","Requirement already satisfied: numpy>=1.19 in /opt/homebrew/Caskroom/miniforge/base/envs/environment10/lib/python3.9/site-packages (from nibabel) (1.23.5)\n","Requirement already satisfied: packaging>=17 in /opt/homebrew/Caskroom/miniforge/base/envs/environment10/lib/python3.9/site-packages (from nibabel) (22.0)\n","Installing collected packages: nibabel\n","Successfully installed nibabel-5.1.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install nibabel tqdm"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"num_samples should be a positive integer value, but got num_samples=0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m adc_files \u001b[39m=\u001b[39m []\n\u001b[1;32m    113\u001b[0m dataset \u001b[39m=\u001b[39m BrainDataset(t1w_files, t2w_files, fa_files, adc_files, transform\u001b[39m=\u001b[39mCompose([torch\u001b[39m.\u001b[39mtensor]))\n\u001b[0;32m--> 114\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_workers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    116\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m unet \u001b[39m=\u001b[39m initialize_unet(in_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, out_channels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/environment10/lib/python3.9/site-packages/torch/utils/data/dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 344\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/environment10/lib/python3.9/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n","\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import Compose\n","import nibabel as nib\n","import numpy as np\n","from tqdm import tqdm\n","from torchvision.transforms import Compose\n","\n","\n","# Custom dataset class for handling NIfTI files\n","class BrainDataset(Dataset):\n","    def __init__(self, t1w_files, t2w_files, fa_files, adc_files, transform=None):\n","        self.t1w_files = t1w_files\n","        self.t2w_files = t2w_files\n","        self.fa_files = fa_files\n","        self.adc_files = adc_files\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.t1w_files)\n","\n","    def __getitem__(self, idx):\n","        t1w_image = nib.load(self.t1w_files[idx]).get_fdata()\n","        t2w_image = nib.load(self.t2w_files[idx]).get_fdata()\n","        fa_image = nib.load(self.fa_files[idx]).get_fdata()\n","        adc_image = nib.load(self.adc_files[idx]).get_fdata()\n","\n","        input_image = np.stack([t1w_image, t2w_image], axis=0)\n","        target_image = np.stack([fa_image, adc_image], axis=0)\n","\n","        if self.transform:\n","            input_image = self.transform(input_image)\n","            target_image = self.transform(target_image)\n","\n","        return input_image, target_image\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.middle = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        enc = self.encoder(x)\n","        middle = self.middle(enc)\n","        dec = self.decoder(middle)\n","        out = self.final(dec)\n","        return out\n","\n","# Function for initializing the U-Net model\n","def initialize_unet(in_channels, out_channels):\n","    return UNet(in_channels, out_channels)\n","\n","# Function for training the U-Net model\n","def train_unet(unet, dataloader, device, epochs=100, learning_rate=0.001):\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(unet.parameters(), lr=learning_rate)\n","\n","    unet.train()\n","    unet.to(device)\n","\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for inputs, targets in tqdm(dataloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = unet(inputs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloader)}\")\n","\n","    print(\"Training completed.\")\n","\n","if __name__ == \"__main__\":\n","    data_dir = os.path.join('..', 'data')\n","\n","    # Replace these lists with the paths to your training dataset\n","    t1w_files = []\n","    t2w_files = []\n","    fa_files = []\n","    adc_files = []\n","\n","    dataset = BrainDataset(t1w_files, t2w_files, fa_files, adc_files, transform=Compose([torch.tensor]))\n","    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2)\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    unet = initialize_unet(in_channels=2, out_channels=2)\n","    train_unet(unet, dataloader, device, epochs=100, learning_rate=0.001)\n","\n","    # Save the trained model\n","    torch.save(unet.state_dict(), os.path.join(data_dir, \"unet_model.pth\"))\n","\n","    print(\"Model saved.\")\n"]}],"metadata":{"kernelspec":{"display_name":"environment10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
