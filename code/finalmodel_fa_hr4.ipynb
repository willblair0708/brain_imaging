{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for handling NIfTI files\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, t1w_files, t2w_files, fa_files, adc_files, transform=None):\n",
    "        self.t1w_files = t1w_files\n",
    "        self.t2w_files = t2w_files\n",
    "        self.fa_files = fa_files\n",
    "        # self.adc_files = adc_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t1w_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t1w_image = nib.load(self.t1w_files[idx]).get_fdata()\n",
    "        t2w_image = nib.load(self.t2w_files[idx]).get_fdata()\n",
    "        fa_image = nib.load(self.fa_files[idx]).get_fdata()\n",
    "        # adc_image = nib.load(self.adc_files[idx]).get_fdata()\n",
    "\n",
    "        # input_image = np.stack([t1w_image, t2w_image], axis=0)\n",
    "        t1w_image = np.stack([t1w_image], axis=0)\n",
    "        # target_image = np.stack([fa_image, adc_image], axis=0)\n",
    "        t2w_image = np.stack([t2w_image], axis=0)\n",
    "        fa_image = np.stack([fa_image], axis=0)\n",
    "\n",
    "        # if self.transform:\n",
    "            # input_image = self.transform(input_image)\n",
    "            # target_image = self.transform(target_image)\n",
    "\n",
    "        # return input_image, target_image\n",
    "        return t1w_image, t2w_image, fa_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001/normalized/T1w_1mm_normalized.nii.gz\n",
      "002/normalized/T1w_1mm_normalized.nii.gz\n",
      "003/normalized/T1w_1mm_normalized.nii.gz\n",
      "004/normalized/T1w_1mm_normalized.nii.gz\n",
      "005/normalized/T1w_1mm_normalized.nii.gz\n",
      "006/normalized/T1w_1mm_normalized.nii.gz\n",
      "007/normalized/T1w_1mm_normalized.nii.gz\n",
      "008/normalized/T1w_1mm_normalized.nii.gz\n",
      "009/normalized/T1w_1mm_normalized.nii.gz\n",
      "010/normalized/T1w_1mm_normalized.nii.gz\n",
      "011/normalized/T1w_1mm_normalized.nii.gz\n",
      "012/normalized/T1w_1mm_normalized.nii.gz\n",
      "013/normalized/T1w_1mm_normalized.nii.gz\n",
      "014/normalized/T1w_1mm_normalized.nii.gz\n",
      "015/normalized/T1w_1mm_normalized.nii.gz\n",
      "016/normalized/T1w_1mm_normalized.nii.gz\n",
      "017/normalized/T1w_1mm_normalized.nii.gz\n",
      "018/normalized/T1w_1mm_normalized.nii.gz\n",
      "019/normalized/T1w_1mm_normalized.nii.gz\n",
      "020/normalized/T1w_1mm_normalized.nii.gz\n",
      "021/normalized/T1w_1mm_normalized.nii.gz\n",
      "022/normalized/T1w_1mm_normalized.nii.gz\n",
      "023/normalized/T1w_1mm_normalized.nii.gz\n",
      "024/normalized/T1w_1mm_normalized.nii.gz\n",
      "025/normalized/T1w_1mm_normalized.nii.gz\n",
      "026/normalized/T1w_1mm_normalized.nii.gz\n",
      "027/normalized/T1w_1mm_normalized.nii.gz\n",
      "028/normalized/T1w_1mm_normalized.nii.gz\n",
      "029/normalized/T1w_1mm_normalized.nii.gz\n",
      "030/normalized/T1w_1mm_normalized.nii.gz\n",
      "031/normalized/T1w_1mm_normalized.nii.gz\n",
      "032/normalized/T1w_1mm_normalized.nii.gz\n",
      "033/normalized/T1w_1mm_normalized.nii.gz\n",
      "034/normalized/T1w_1mm_normalized.nii.gz\n",
      "035/normalized/T1w_1mm_normalized.nii.gz\n",
      "036/normalized/T1w_1mm_normalized.nii.gz\n",
      "037/normalized/T1w_1mm_normalized.nii.gz\n",
      "038/normalized/T1w_1mm_normalized.nii.gz\n",
      "039/normalized/T1w_1mm_normalized.nii.gz\n",
      "040/normalized/T1w_1mm_normalized.nii.gz\n",
      "041/normalized/T1w_1mm_normalized.nii.gz\n",
      "042/normalized/T1w_1mm_normalized.nii.gz\n",
      "043/normalized/T1w_1mm_normalized.nii.gz\n",
      "044/normalized/T1w_1mm_normalized.nii.gz\n",
      "045/normalized/T1w_1mm_normalized.nii.gz\n",
      "046/normalized/T1w_1mm_normalized.nii.gz\n",
      "047/normalized/T1w_1mm_normalized.nii.gz\n",
      "048/normalized/T1w_1mm_normalized.nii.gz\n",
      "049/normalized/T1w_1mm_normalized.nii.gz\n",
      "050/normalized/T1w_1mm_normalized.nii.gz\n",
      "051/normalized/T1w_1mm_normalized.nii.gz\n",
      "052/normalized/T1w_1mm_normalized.nii.gz\n",
      "053/normalized/T1w_1mm_normalized.nii.gz\n",
      "054/normalized/T1w_1mm_normalized.nii.gz\n",
      "055/normalized/T1w_1mm_normalized.nii.gz\n",
      "056/normalized/T1w_1mm_normalized.nii.gz\n",
      "057/normalized/T1w_1mm_normalized.nii.gz\n",
      "058/normalized/T1w_1mm_normalized.nii.gz\n",
      "059/normalized/T1w_1mm_normalized.nii.gz\n",
      "060/normalized/T1w_1mm_normalized.nii.gz\n",
      "061/normalized/T1w_1mm_normalized.nii.gz\n",
      "062/normalized/T1w_1mm_normalized.nii.gz\n",
      "063/normalized/T1w_1mm_normalized.nii.gz\n",
      "064/normalized/T1w_1mm_normalized.nii.gz\n",
      "065/normalized/T1w_1mm_normalized.nii.gz\n",
      "066/normalized/T1w_1mm_normalized.nii.gz\n",
      "067/normalized/T1w_1mm_normalized.nii.gz\n",
      "068/normalized/T1w_1mm_normalized.nii.gz\n",
      "069/normalized/T1w_1mm_normalized.nii.gz\n",
      "111/normalized/T1w_1mm_normalized.nii.gz\n",
      "112/normalized/T1w_1mm_normalized.nii.gz\n",
      "113/normalized/T1w_1mm_normalized.nii.gz\n",
      "114/normalized/T1w_1mm_normalized.nii.gz\n",
      "115/normalized/T1w_1mm_normalized.nii.gz\n",
      "116/normalized/T1w_1mm_normalized.nii.gz\n",
      "117/normalized/T1w_1mm_normalized.nii.gz\n",
      "118/normalized/T1w_1mm_normalized.nii.gz\n",
      "119/normalized/T1w_1mm_normalized.nii.gz\n",
      "120/normalized/T1w_1mm_normalized.nii.gz\n",
      "121/normalized/T1w_1mm_normalized.nii.gz\n",
      "122/normalized/T1w_1mm_normalized.nii.gz\n",
      "123/normalized/T1w_1mm_normalized.nii.gz\n",
      "124/normalized/T1w_1mm_normalized.nii.gz\n",
      "125/normalized/T1w_1mm_normalized.nii.gz\n",
      "126/normalized/T1w_1mm_normalized.nii.gz\n",
      "127/normalized/T1w_1mm_normalized.nii.gz\n",
      "128/normalized/T1w_1mm_normalized.nii.gz\n",
      "129/normalized/T1w_1mm_normalized.nii.gz\n",
      "130/normalized/T1w_1mm_normalized.nii.gz\n",
      "131/normalized/T1w_1mm_normalized.nii.gz\n",
      "132/normalized/T1w_1mm_normalized.nii.gz\n",
      "133/normalized/T1w_1mm_normalized.nii.gz\n",
      "134/normalized/T1w_1mm_normalized.nii.gz\n",
      "135/normalized/T1w_1mm_normalized.nii.gz\n",
      "136/normalized/T1w_1mm_normalized.nii.gz\n",
      "137/normalized/T1w_1mm_normalized.nii.gz\n",
      "138/normalized/T1w_1mm_normalized.nii.gz\n",
      "139/normalized/T1w_1mm_normalized.nii.gz\n",
      "140/normalized/T1w_1mm_normalized.nii.gz\n",
      "141/normalized/T1w_1mm_normalized.nii.gz\n",
      "142/normalized/T1w_1mm_normalized.nii.gz\n",
      "143/normalized/T1w_1mm_normalized.nii.gz\n",
      "144/normalized/T1w_1mm_normalized.nii.gz\n",
      "145/normalized/T1w_1mm_normalized.nii.gz\n",
      "146/normalized/T1w_1mm_normalized.nii.gz\n",
      "147/normalized/T1w_1mm_normalized.nii.gz\n",
      "148/normalized/T1w_1mm_normalized.nii.gz\n",
      "149/normalized/T1w_1mm_normalized.nii.gz\n",
      "150/normalized/T1w_1mm_normalized.nii.gz\n",
      "151/normalized/T1w_1mm_normalized.nii.gz\n",
      "152/normalized/T1w_1mm_normalized.nii.gz\n",
      "153/normalized/T1w_1mm_normalized.nii.gz\n",
      "154/normalized/T1w_1mm_normalized.nii.gz\n",
      "155/normalized/T1w_1mm_normalized.nii.gz\n",
      "156/normalized/T1w_1mm_normalized.nii.gz\n",
      "157/normalized/T1w_1mm_normalized.nii.gz\n",
      "158/normalized/T1w_1mm_normalized.nii.gz\n",
      "159/normalized/T1w_1mm_normalized.nii.gz\n",
      "160/normalized/T1w_1mm_normalized.nii.gz\n",
      "161/normalized/T1w_1mm_normalized.nii.gz\n",
      "162/normalized/T1w_1mm_normalized.nii.gz\n",
      "164/normalized/T1w_1mm_normalized.nii.gz\n",
      "165/normalized/T1w_1mm_normalized.nii.gz\n",
      "166/normalized/T1w_1mm_normalized.nii.gz\n",
      "167/normalized/T1w_1mm_normalized.nii.gz\n",
      "168/normalized/T1w_1mm_normalized.nii.gz\n",
      "169/normalized/T1w_1mm_normalized.nii.gz\n",
      "170/normalized/T1w_1mm_normalized.nii.gz\n",
      "171/normalized/T1w_1mm_normalized.nii.gz\n",
      "172/normalized/T1w_1mm_normalized.nii.gz\n",
      "173/normalized/T1w_1mm_normalized.nii.gz\n",
      "174/normalized/T1w_1mm_normalized.nii.gz\n",
      "175/normalized/T1w_1mm_normalized.nii.gz\n",
      "176/normalized/T1w_1mm_normalized.nii.gz\n",
      "177/normalized/T1w_1mm_normalized.nii.gz\n",
      "178/normalized/T1w_1mm_normalized.nii.gz\n",
      "179/normalized/T1w_1mm_normalized.nii.gz\n",
      "180/normalized/T1w_1mm_normalized.nii.gz\n",
      "181/normalized/T1w_1mm_normalized.nii.gz\n",
      "182/normalized/T1w_1mm_normalized.nii.gz\n",
      "183/normalized/T1w_1mm_normalized.nii.gz\n",
      "184/normalized/T1w_1mm_normalized.nii.gz\n",
      "185/normalized/T1w_1mm_normalized.nii.gz\n",
      "186/normalized/T1w_1mm_normalized.nii.gz\n",
      "187/normalized/T1w_1mm_normalized.nii.gz\n",
      "188/normalized/T1w_1mm_normalized.nii.gz\n",
      "189/normalized/T1w_1mm_normalized.nii.gz\n",
      "190/normalized/T1w_1mm_normalized.nii.gz\n",
      "191/normalized/T1w_1mm_normalized.nii.gz\n",
      "192/normalized/T1w_1mm_normalized.nii.gz\n",
      "193/normalized/T1w_1mm_normalized.nii.gz\n",
      "194/normalized/T1w_1mm_normalized.nii.gz\n",
      "195/normalized/T1w_1mm_normalized.nii.gz\n",
      "196/normalized/T1w_1mm_normalized.nii.gz\n",
      "197/normalized/T1w_1mm_normalized.nii.gz\n",
      "198/normalized/T1w_1mm_normalized.nii.gz\n",
      "199/normalized/T1w_1mm_normalized.nii.gz\n",
      "200/normalized/T1w_1mm_normalized.nii.gz\n",
      "Total number of samples: 158\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.chdir('../data/output14')\n",
    "\n",
    "t1w_files = []\n",
    "t2w_files = []\n",
    "fa_files = []\n",
    "adc_files = []\n",
    "\n",
    "# Loop for patient folders from 000 to 069\n",
    "for patient_id in range(1,70):\n",
    "    patient_folder = str(patient_id).zfill(3)\n",
    "    registered_path = os.path.join(patient_folder, \"registered\")\n",
    "    registered2_path = os.path.join(patient_folder, \"registered2\")\n",
    "    normalized_path = os.path.join(patient_folder, \"normalized\")\n",
    "\n",
    "    try:\n",
    "        t1w_files.append(os.path.join(normalized_path, \"T1w_1mm_normalized.nii.gz\"))\n",
    "        t2w_files.append(os.path.join(registered_path, \"T2w_registered.nii.gz\"))\n",
    "        adc_files.append(os.path.join(registered2_path, \"ADC_registered.nii.gz\"))\n",
    "        fa_files.append(os.path.join(registered2_path, \"FA_registered.nii.gz\"))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for patient folder: {patient_folder}\")\n",
    "\n",
    "# Loop for patient folders from 111 to 200\n",
    "for patient_id in range(111, 201):\n",
    "    if patient_id == 163:\n",
    "        continue  # Skip patient folder 163\n",
    "    patient_folder = str(patient_id)\n",
    "    registered_path = os.path.join(patient_folder, \"registered\")\n",
    "    registered2_path = os.path.join(patient_folder, \"registered2\")\n",
    "    normalized_path = os.path.join(patient_folder, \"normalized\")\n",
    "\n",
    "    try:\n",
    "        t1w_files.append(os.path.join(normalized_path, \"T1w_1mm_normalized.nii.gz\"))\n",
    "        t2w_files.append(os.path.join(registered_path, \"T2w_registered.nii.gz\"))\n",
    "        adc_files.append(os.path.join(registered2_path, \"ADC_registered.nii.gz\"))\n",
    "        fa_files.append(os.path.join(registered2_path, \"FA_registered.nii.gz\"))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for patient folder: {patient_folder}\")\n",
    "\n",
    "dataset = BrainDataset(\n",
    "    t1w_files, t2w_files, fa_files, adc_files, transform=Compose([torch.tensor])\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 0 for FA, 1 for ADC\n",
    "output_modality = 0\n",
    "\n",
    "# Print t1w files on separate lines\n",
    "for t1w_file in t1w_files:\n",
    "    print(t1w_file)\n",
    "\n",
    "print(\"Total number of samples:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/79 [00:03<01:43,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/79 [00:04<01:33,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/79 [00:05<01:34,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/79 [00:06<01:31,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/79 [00:07<01:20,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/79 [00:08<01:13,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/79 [00:09<01:09,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/79 [00:10<01:05,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 10/79 [00:11<01:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/79 [00:11<01:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/79 [00:12<00:59,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/79 [00:13<00:57,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/79 [00:14<00:56,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/79 [00:15<00:54,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/79 [00:16<00:53,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 17/79 [00:17<00:52,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 18/79 [00:17<00:52,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/79 [00:18<00:51,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/79 [00:19<00:50,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 21/79 [00:20<00:49,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/79 [00:21<00:48,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/79 [00:22<00:48,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/79 [00:23<00:47,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 25/79 [00:23<00:46,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 26/79 [00:24<00:45,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/79 [00:25<00:44,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/79 [00:26<00:43,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 29/79 [00:27<00:42,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/79 [00:28<00:42,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/79 [00:29<00:41,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 32/79 [00:30<00:42,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 33/79 [00:31<00:46,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 34/79 [00:32<00:50,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/79 [00:34<00:51,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 36/79 [00:35<00:51,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 37/79 [00:36<00:51,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/79 [00:37<00:50,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/79 [00:39<00:49,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 40/79 [00:39<00:44,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 41/79 [00:40<00:39,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 42/79 [00:41<00:36,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/79 [00:42<00:38,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 44/79 [00:44<00:39,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 45/79 [00:45<00:40,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 46/79 [00:46<00:36,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/79 [00:47<00:33,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 48/79 [00:48<00:30,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 49/79 [00:49<00:28,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 50/79 [00:49<00:26,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 51/79 [00:50<00:24,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 52/79 [00:51<00:23,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 53/79 [00:52<00:22,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/79 [00:53<00:22,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 55/79 [00:54<00:20,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 56/79 [00:54<00:19,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 57/79 [00:55<00:18,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 58/79 [00:56<00:17,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 59/79 [00:57<00:17,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 60/79 [00:58<00:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 61/79 [00:59<00:15,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/79 [01:00<00:14,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 63/79 [01:00<00:13,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 64/79 [01:01<00:12,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 65/79 [01:02<00:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 66/79 [01:03<00:10,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 67/79 [01:04<00:10,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 68/79 [01:05<00:09,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 69/79 [01:06<00:08,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 70/79 [01:06<00:07,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 71/79 [01:07<00:06,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 72/79 [01:08<00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 73/79 [01:09<00:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 74/79 [01:10<00:04,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 75/79 [01:11<00:03,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 76/79 [01:11<00:02,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 77/79 [01:12<00:01,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 78/79 [01:13<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:14<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 182, 218, 182])\n",
      "torch.Size([2, 1, 182, 218, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for inputs, targets in tqdm(dataloader):\n",
    "#     inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "#     print(inputs.shape)\n",
    "#     print(targets.shape)\n",
    "\n",
    "for t1, t2, fa in tqdm(dataloader):\n",
    "    t1, t2, fa = t1.to(device), t2.to(device), fa.to(device)\n",
    "\n",
    "    print(t1.shape)\n",
    "    print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 182, 218, 182)\n",
    "\n",
    "nc = 1 # num channels\n",
    "\n",
    "ngf = 32 # size of feature maps in generator\n",
    "\n",
    "ndf = 32 # size of feature maps in discriminator\n",
    "\n",
    "num_epochs = 200 # 200\n",
    "\n",
    "lr = 0.0002\n",
    "\n",
    "betas = (0.5, 0.999) # beta1 hyperparameter for Adam optimizers\n",
    "\n",
    "ngpu = 1 # number of GPUs available, 0 for CPU mode\n",
    "\n",
    "batch_size = 128 # batch size during training\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "ngpu = 1 # Number of GPUs available. Use 0 for CPU mode.\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(\n",
    "            # input is 1 x 182 x 218 x 182\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            # input is 32 x 91 x 109 x 91\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            # input is 64 x 45 x 54 x 45\n",
    "            nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=1),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "            nn.Flatten(),\n",
    "            # input is 128 x 22 x 27 x 22\n",
    "            nn.Linear(1672704, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU()\n",
    "            # nn.Linear(128, 64),\n",
    "            # nn.Linear(64, 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Sigmoid(), # is this needed?\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_model = ConvNet().to(device)\n",
    "t2_model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "img_shape = (2, 182, 218, 182)\n",
    "\n",
    "# Define the generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, 128 * 22 * 27 * 22),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(128 * 22 * 27 * 22)\n",
    "        )\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose3d(32, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layer(x)\n",
    "        x = x.view(x.shape[0], 128, 22, 27, 22) # reshaping tensor\n",
    "        x = self.conv_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout3d(0.25),\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout3d(0.25),\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(64 * 23* 28 * 23, 128),\n",
    "            # nn.LeakyReLU(0.2), #inplace=True\n",
    "            # nn.Linear(128, 64),\n",
    "            # nn.LeakyReLU(0.2), #inplace=True\n",
    "            # nn.Linear(64, 1),\n",
    "            # nn.Linear(64 * 36 * 43 * 36, 1),\n",
    "            nn.Linear(7448320, 1), # 64 x 45 x 54 x 45\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator and generator models\n",
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "\n",
    "# generator.apply(weights_init)\n",
    "# discriminator.apply(weights_init)\n",
    "\n",
    "# Define the loss function and optimizer for the discriminator and generator\n",
    "adversarial_loss = nn.BCELoss()\n",
    "al_w = 1\n",
    "generative_loss = nn.MSELoss()\n",
    "gl_w = 0.1\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
    "optimizer_T1 = torch.optim.Adam(t1_model.parameters(), lr=lr*10, betas=betas)\n",
    "optimizer_T2 = torch.optim.Adam(t2_model.parameters(), lr=lr*10, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Train the models\\nfor epoch in range(num_epochs):\\n    i = 0\\n    for t1, t2, fa in tqdm(dataloader):\\n        t1, t2, fa = t1.to(device), t2.to(device), fa.to(device)\\n        \\n        # update D: maximize log(D(x)) + log(1 - D(G(z)))\\n        # train with all-real batch\\n        discriminator.zero_grad()\\n        real_images = fa.float()\\n        real_labels = torch.ones(real_images.shape[0], 1).cuda()\\n        real_predictions = discriminator(real_images)\\n        real_loss = adversarial_loss(real_predictions, real_labels)\\n        real_loss.backward()\\n\\n        # create latent space and update D with fake image\\n        t1_latent = t1_model(t1.float()) \\n        t2_latent = t2_model(t2.float())\\n        # latent = t1_latent + t2_latent\\n        latent = torch.concat((t1_latent.detach(), t2_latent.detach()), 1)\\n        fake_images = generator(latent)\\n        fake_images = torch.nn.functional.pad(fake_images, pad=(3, 3, 1, 1, 3, 3), mode=\\'replicate\\') # kinda sketch \\n        fake_labels = torch.zeros(fake_images.shape[0], 1).cuda()\\n        fake_predictions = discriminator(fake_images.detach())\\n        fake_loss = adversarial_loss(fake_predictions, fake_labels)\\n        fake_loss.backward()\\n\\n        discriminator_loss = real_loss + fake_loss\\n        optimizer_D.step()\\n\\n        # update G network: maximize log(D(G(z)))\\n        generator.zero_grad()\\n        t1_model.zero_grad()\\n        t2_model.zero_grad()\\n\\n        fake_images = generator(latent)\\n        fake_images = torch.nn.functional.pad(fake_images, pad=(3, 3, 1, 1, 3, 3), mode=\\'replicate\\') # kinda sketch \\n        fake_predictions = discriminator(fake_images)\\n        errG = adversarial_loss(fake_predictions, real_labels)\\n        errR = generative_loss(fake_images, fa.float())\\n        generator_loss = al_w*errG + gl_w*errR\\n        generator_loss.backward()\\n        optimizer_G.step()     \\n        optimizer_T1.step()\\n        optimizer_T2.step()   \\n\\n        # output training stats\\n        #if i % 50 == 0:\\n        G_losses.append(generator_loss.item())\\n        D_losses.append(discriminator_loss.item())\\n\\n        # Print the losses\\n        if i % 100 == 0:\\n            print(\"Epoch [%d/%d], Step [%d/%d], Discriminator Loss: %.4f, Generator Loss: %.4f\"\\n                  % (epoch, num_epochs, i, len(dataloader), discriminator_loss.item(), generator_loss.item()))\\n            torch.save(generator.state_dict(), \"generator.pt\")\\n            torch.save(discriminator.state_dict(), \"discriminator.pt\")\\n            torch.save(t1_model.state_dict(), \"t1_model.pt\")\\n            torch.save(t2_model.state_dict(), \"t2_model.pt\")\\n\\n            torch.cuda.empty_cache()\\n            \\n        i += 1\\n            \\n        iters += 1\\n\\n        # t1_latent = t1_model(t1) \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "## Change to True / False if you do / do not want \n",
    "## to load the previously saved state dictionaries\n",
    "load = True\n",
    "if load:\n",
    "    generator.load_state_dict(torch.load(\"generator.pt\"))\n",
    "    discriminator.load_state_dict(torch.load(\"discriminator.pt\"))\n",
    "    t1_model.load_state_dict(torch.load(\"t1_model.pt\"))\n",
    "    t2_model.load_state_dict(torch.load(\"t2_model.pt\"))\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 1\n",
    "img_shape = (batch_size, 182, 218, 182)\n",
    "\n",
    "# Train the models\n",
    "for epoch in range(num_epochs):\n",
    "    i = 0\n",
    "    for t1, t2, fa in tqdm(dataloader):\n",
    "        t1, t2, fa = t1.to(device), t2.to(device), fa.to(device)\n",
    "        \n",
    "        # update D: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # train with all-real batch\n",
    "        discriminator.zero_grad()\n",
    "        real_images = fa.float()\n",
    "        real_labels = torch.ones(real_images.shape[0], 1).cuda()\n",
    "        real_predictions = discriminator(real_images)\n",
    "        real_loss = adversarial_loss(real_predictions, real_labels)\n",
    "        real_loss.backward()\n",
    "\n",
    "        # create latent space and update D with fake image\n",
    "        t1_latent = t1_model(t1.float()) \n",
    "        t2_latent = t2_model(t2.float())\n",
    "        # latent = t1_latent + t2_latent\n",
    "        latent = torch.concat((t1_latent.detach(), t2_latent.detach()), 1)\n",
    "        fake_images = generator(latent)\n",
    "        fake_images = torch.nn.functional.pad(fake_images, pad=(3, 3, 1, 1, 3, 3), mode='replicate') # kinda sketch \n",
    "        fake_labels = torch.zeros(fake_images.shape[0], 1).cuda()\n",
    "        fake_predictions = discriminator(fake_images.detach())\n",
    "        fake_loss = adversarial_loss(fake_predictions, fake_labels)\n",
    "        fake_loss.backward()\n",
    "\n",
    "        discriminator_loss = real_loss + fake_loss\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # update G network: maximize log(D(G(z)))\n",
    "        generator.zero_grad()\n",
    "        t1_model.zero_grad()\n",
    "        t2_model.zero_grad()\n",
    "\n",
    "        fake_images = generator(latent)\n",
    "        fake_images = torch.nn.functional.pad(fake_images, pad=(3, 3, 1, 1, 3, 3), mode='replicate') # kinda sketch \n",
    "        fake_predictions = discriminator(fake_images)\n",
    "        errG = adversarial_loss(fake_predictions, real_labels)\n",
    "        errR = generative_loss(fake_images, fa.float())\n",
    "        generator_loss = al_w*errG + gl_w*errR\n",
    "        generator_loss.backward()\n",
    "        optimizer_G.step()     \n",
    "        optimizer_T1.step()\n",
    "        optimizer_T2.step()   \n",
    "\n",
    "        # output training stats\n",
    "        #if i % 50 == 0:\n",
    "        G_losses.append(generator_loss.item())\n",
    "        D_losses.append(discriminator_loss.item())\n",
    "\n",
    "        # Print the losses\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Discriminator Loss: %.4f, Generator Loss: %.4f\"\n",
    "                  % (epoch, num_epochs, i, len(dataloader), discriminator_loss.item(), generator_loss.item()))\n",
    "            torch.save(generator.state_dict(), \"generator.pt\")\n",
    "            torch.save(discriminator.state_dict(), \"discriminator.pt\")\n",
    "            torch.save(t1_model.state_dict(), \"t1_model.pt\")\n",
    "            torch.save(t2_model.state_dict(), \"t2_model.pt\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        i += 1\n",
    "            \n",
    "        iters += 1\n",
    "\n",
    "        # t1_latent = t1_model(t1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "os.chdir('../output14')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "t1_model = ConvNet().to(device)\n",
    "t2_model = ConvNet().to(device)\n",
    "\n",
    "# Load the trained weights\n",
    "generator.load_state_dict(torch.load(\"generator.pt\"))\n",
    "discriminator.load_state_dict(torch.load(\"discriminator.pt\"))\n",
    "t1_model.load_state_dict(torch.load(\"t1_model.pt\"))\n",
    "t2_model.load_state_dict(torch.load(\"t2_model.pt\"))\n",
    "\n",
    "def generate_img(t1w_path, t2w_path):\n",
    "    # Load the images as SimpleITK images\n",
    "    t1w_image_sitk = sitk.ReadImage(t1w_path)\n",
    "    t2w_image_sitk = sitk.ReadImage(t2w_path)\n",
    "\n",
    "    # Convert the images to numpy arrays\n",
    "    t1w_image = sitk.GetArrayFromImage(t1w_image_sitk)\n",
    "    t2w_image = sitk.GetArrayFromImage(t2w_image_sitk)\n",
    "\n",
    "    # Convert the images to torch tensors and add a batch dimension\n",
    "    t1w_image = torch.from_numpy(t1w_image).unsqueeze(0).float().to(device)\n",
    "    t2w_image = torch.from_numpy(t2w_image).unsqueeze(0).float().to(device)\n",
    "\n",
    "    # Pass the images through the models\n",
    "    t1_latent = t1_model(t1w_image)\n",
    "    t2_latent = t2_model(t2w_image)\n",
    "    latent = torch.cat((t1_latent, t2_latent), 1)\n",
    "    generated_image = generator(latent)\n",
    "    generated_image = torch.nn.functional.pad(generated_image, pad=(3, 3, 1, 1, 3, 3), mode='replicate')\n",
    "\n",
    "    # Convert the tensor back to numpy\n",
    "    generated_image = generated_image.squeeze().cpu().detach().numpy()\n",
    "\n",
    "    # Create a SimpleITK image from the numpy array\n",
    "    sitk_image = sitk.GetImageFromArray(generated_image)\n",
    "\n",
    "    # Resample the image\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetSize((145, 174, 145))\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resampled_image = resampler.Execute(sitk_image)\n",
    "\n",
    "    # Convert the resampled image back to a numpy array\n",
    "    resampled_array = sitk.GetArrayFromImage(resampled_image)\n",
    "\n",
    "    return resampled_array\n",
    "\n",
    "# Call the function with the paths to your T1W and T2W images\n",
    "synthesized_fa_image = generate_img('../output8/normalized/T1w_1mm_normalized.nii.gz', '../output8/registered/T2w_align.nii.gz')\n",
    "\n",
    "# Save the synthesized image to a file\n",
    "sitk.WriteImage(sitk.GetImageFromArray(synthesized_fa_image), 'synthesized_fa_image.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5fc14744308f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mt2w_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2w_image_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1w_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2w_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Visualize output vs actual file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-16b61712219d>\u001b[0m in \u001b[0;36mgenerate_img\u001b[0;34m(t1w_image, t2w_image)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mt1w_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1w_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt2w_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2w_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mt1_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1w_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mt2_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2w_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7c06b0dfa9bd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         )\n\u001b[1;32m   2447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256])"
     ]
    }
   ],
   "source": [
    "# Change the working directory to the \"data\" folder\n",
    "!pwd\n",
    "os.chdir('../output8'))\n",
    "\n",
    "# Get the list of patient folders\n",
    "patient_folders = [folder for folder in os.listdir() if os.path.isdir(folder)]\n",
    "\n",
    "# Register images to T1w space using Diffeomorphic Demons\n",
    "for patient_folder in patient_folders:\n",
    "    output_folder = os.path.abspath(patient_folder)\n",
    "\n",
    "    # Create the output folder for the registered images\n",
    "    synthesized_output_folder = os.path.join(output_folder, \"synthesized\")\n",
    "    os.makedirs(synthesized_output_folder, exist_ok=True)\n",
    "\n",
    "    t1w_image_path = os.path.join(output_folder, \"normalized\", \"T1w_1mm_normalized.nii.gz\")\n",
    "    t2w_image_path = os.path.join(output_folder, \"registered\", \"T2w_align.nii.gz\")\n",
    "    #fa_image_path = os.path.join(output_folder, \"registered\", \"FA_1.25mm_normalized.nii.gz\")\n",
    "    #adc_image_path = os.path.join(output_folder, \"registered\", \"ADC_1.25mm_normalized.nii.gz\")\n",
    "\n",
    "    # synthesized_image_path = os.path.join(synthesized_output_folder, \"ADC_synthesized.nii.gz\")\n",
    "    synthesized_image_path = os.path.join(synthesized_output_folder, \"FA_synthesized.nii.gz\")\n",
    "\n",
    "    t1w_image_file = nib.load(t1w_image_path)\n",
    "    t1w_image = t1w_image_file.get_fdata()\n",
    "    t2w_image_file = nib.load(t2w_image_path)\n",
    "    t2w_image = t2w_image_file.get_fdata()\n",
    "\n",
    "    generated_image = generate_img(t1w_image, t2w_image)\n",
    "\n",
    "    # visualize output vs actual file\n",
    "    plt.rcParams[\"figure.figsize\"]=20,20\n",
    "    plt.figure()\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(generated_image[:,:,100])\n",
    "    plt.title('Generated Image')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.title('Actual Image')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(generated_image[105,:,:])\n",
    "    plt.title('Generated Image')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.title('Actual Image')\n",
    "    plt.show()\n",
    "\n",
    "    sitk.WriteImage(generated_image, synthesized_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
